{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "- Load the train data and using all your knowledge try to explore the different statistical properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "train_data = pd.read_csv(r'C:\\Users\\Vinit.Shetty\\Documents\\DS\\UCL- NLP1\\train.csv')\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and Preprocess the data\n",
    "\n",
    "- Retaining only alphabets (Using regular expressions)\n",
    "- Removing stopwords (Using nltk library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# retain only alphabets\n",
    "train_data['TITLE'] = train_data['TITLE'].apply(lambda x:re.sub(\"[^a-zA-Z]\", \" \",x))\n",
    "\n",
    "# convert to lowercase and tokenize\n",
    "train_data['TITLE'] = train_data['TITLE'].apply(lambda x:x.lower().split())\n",
    "\n",
    "# remove stopwords\n",
    "train_data['TITLE'] = train_data['TITLE'].apply(lambda x:[i for i in x if i not in stop])\n",
    "\n",
    "# join list elements\n",
    "train_data['TITLE'] = train_data['TITLE'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data[\"TITLE\"], train_data[\"CATEGORY\"],\n",
    "                                                                            test_size = 0.2,random_state=3)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "- Now let's come to the actual task, using any classifier, predict the `CATEGORY`. Use different techniques you have learned to imporove the performance of the model.\n",
    "- Try improving upon the `accuracy_score` ([Accuracy Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# initialize tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "# fit and transform with count vectorizer\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# fit and transform with tfidf vectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272641188394218 0.9295870507642002\n"
     ]
    }
   ],
   "source": [
    "nb_1 = MultinomialNB()\n",
    "nb_2 = MultinomialNB()\n",
    "\n",
    "# fit on count vectorizer training data\n",
    "nb_1.fit(X_train_count, Y_train)\n",
    "\n",
    "# fit on tfidf vectorizer training data\n",
    "nb_2.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# accuracy with count vectorizer\n",
    "acc_count_nb = accuracy_score(nb_1.predict(X_test_count), Y_test)\n",
    "\n",
    "# accuracy with tfidf vectorizer\n",
    "acc_tfidf_nb = accuracy_score(nb_2.predict(X_test_tfidf), Y_test)\n",
    "\n",
    "# display accuracies\n",
    "print(acc_count_nb, acc_tfidf_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9462026721115008 0.9420746593279773\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# initialize logistic regression\n",
    "logreg_1 = OneVsRestClassifier(LogisticRegression(random_state=10))\n",
    "logreg_2 = OneVsRestClassifier(LogisticRegression(random_state=10))\n",
    "\n",
    "# fit on count vectorizer training data\n",
    "logreg_1.fit(X_train_count, Y_train)\n",
    "\n",
    "# fit on tfidf vectorizer training data\n",
    "logreg_2.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# accuracy with count vectorizer\n",
    "acc_count_logreg = accuracy_score(logreg_1.predict(X_test_count), Y_test)\n",
    "\n",
    "# accuracy with tfidf vectorizer\n",
    "acc_tfidf_logreg = accuracy_score(logreg_2.predict(X_test_tfidf), Y_test)\n",
    "\n",
    "# display accuracies\n",
    "print(acc_count_logreg, acc_tfidf_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test data and creating the sample submission file.\n",
    "\n",
    "- Load the test data and store the `Id` column in a separate variable.\n",
    "- Perform the same operations on the test data that you have performed on the train data.\n",
    "- Create the submission file as a `csv` file consisting of the `Id` column from the test data and your prediction as the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Code Starts here\n",
    "# Prediction on test data\n",
    "test = pd.read_csv(r'C:\\Users\\Vinit.Shetty\\Documents\\DS\\UCL- NLP1\\test.csv')\n",
    "Id = test['Id']\n",
    "test['TITLE'] = test['TITLE'].apply(lambda x:re.sub(\"[^a-zA-Z]\", \" \",x))\n",
    "\n",
    "# convert to lowercase and tokenize\n",
    "test['TITLE'] = test['TITLE'].apply(lambda x:x.lower().split())\n",
    "\n",
    "# remove stopwords\n",
    "test['TITLE'] = test['TITLE'].apply(lambda x:[i for i in x if i not in stop])\n",
    "\n",
    "# join list elements\n",
    "test['TITLE'] = test['TITLE'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "\n",
    "test_count = count_vectorizer.transform(test['TITLE'])\n",
    "test_tfidf = tfidf_vectorizer.transform(test['TITLE'])\n",
    "\n",
    "\n",
    "\n",
    "#test['TITLE'] = test['TITLE'].apply(preprocess)\n",
    "test_prediction = logreg_1.predict(test_count)\n",
    "submission = pd.DataFrame({'Id':Id,'CATEGORY':test_prediction})\n",
    "filename = 'submission.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
